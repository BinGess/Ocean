/**
 * è¯­éŸ³è½¬æ–‡æœ¬æœåŠ¡ï¼ˆè±†åŒ… ASRï¼‰
 *
 * æ³¨æ„ï¼šç”±äºæ— æ³•è®¿é—®è±†åŒ…æ–‡æ¡£ï¼Œè¿™é‡Œæä¾›çš„æ˜¯é€šç”¨çš„å®ç°æ¡†æ¶
 * éœ€è¦æ ¹æ®å®é™…çš„è±†åŒ… ASR API æ–‡æ¡£è°ƒæ•´å‚æ•°å’Œå®ç°ç»†èŠ‚
 */

import { DOUBAO_ASR_CONFIG } from '../config/env'

export interface TranscriptionOptions {
  language?: string
  enablePunctuation?: boolean
  enableNumberConversion?: boolean
}

export class TranscriptionService {
  private apiKey: string
  private appId: string
  private endpoint: string

  constructor() {
    this.apiKey = DOUBAO_ASR_CONFIG.apiKey
    this.appId = DOUBAO_ASR_CONFIG.appId
    this.endpoint = DOUBAO_ASR_CONFIG.endpoint
  }

  /**
   * è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆWebSocket æµå¼è¯†åˆ«ï¼‰
   *
   * æ ¹æ®è±†åŒ…æ–‡æ¡£ï¼Œæµå¼è¯†åˆ«é€šå¸¸ä½¿ç”¨ WebSocket åè®®
   */
  async transcribe(
    audioBlob: Blob,
    options?: TranscriptionOptions
  ): Promise<string> {
    // æ–¹æ¡ˆ 1: è±†åŒ… WebSocket æµå¼è¯†åˆ«ï¼ˆéœ€è¦æ ¹æ®æ–‡æ¡£å®ç°ï¼‰
    // return this.transcribeWithWebSocket(audioBlob, options)

    // æ–¹æ¡ˆ 2: å¦‚æœè±†åŒ…æä¾› HTTP APIï¼ˆéœ€è¦æ ¹æ®æ–‡æ¡£å®ç°ï¼‰
    // return this.transcribeWithHTTP(audioBlob, options)

    // ä¸´æ—¶æ–¹æ¡ˆ 3: ä½¿ç”¨æµè§ˆå™¨å†…ç½®çš„ Web Speech APIï¼ˆç”¨äºå¼€å‘æµ‹è¯•ï¼‰
    return this.transcribeWithWebSpeech(audioBlob, options)
  }

  /**
   * ä½¿ç”¨è±†åŒ… WebSocket æµå¼è¯†åˆ«ï¼ˆéœ€è¦æ ¹æ®å®é™…æ–‡æ¡£å®ç°ï¼‰
   *
   * å…¸å‹çš„æµç¨‹ï¼š
   * 1. å»ºç«‹ WebSocket è¿æ¥
   * 2. å‘é€è®¤è¯ä¿¡æ¯å’Œé…ç½®å‚æ•°
   * 3. åˆ†ç‰‡å‘é€éŸ³é¢‘æ•°æ®
   * 4. æ¥æ”¶è¯†åˆ«ç»“æœ
   * 5. å…³é—­è¿æ¥
   */
  private async transcribeWithWebSocket(
    audioBlob: Blob,
    options?: TranscriptionOptions
  ): Promise<string> {
    return new Promise((resolve, reject) => {
      // TODO: æ ¹æ®è±†åŒ…æ–‡æ¡£å®ç° WebSocket è¿æ¥
      const ws = new WebSocket(this.endpoint)

      let transcription = ''

      ws.onopen = () => {
        console.log('ğŸ”Œ WebSocket connected')

        // TODO: å‘é€è®¤è¯å’Œé…ç½®ä¿¡æ¯ï¼ˆæ ¹æ®è±†åŒ…æ–‡æ¡£æ ¼å¼ï¼‰
        const config = {
          app_id: this.appId,
          api_key: this.apiKey,
          language: options?.language || 'zh-CN',
          enable_punctuation: options?.enablePunctuation ?? true,
          enable_number_conversion: options?.enableNumberConversion ?? true
        }

        ws.send(JSON.stringify(config))

        // TODO: åˆ†ç‰‡å‘é€éŸ³é¢‘æ•°æ®
        this.sendAudioData(ws, audioBlob)
      }

      ws.onmessage = (event) => {
        try {
          const result = JSON.parse(event.data)

          // TODO: æ ¹æ®è±†åŒ…å“åº”æ ¼å¼è§£æ
          // é€šå¸¸ä¼šæœ‰ result.text æˆ–ç±»ä¼¼å­—æ®µ
          if (result.text) {
            transcription += result.text
          }

          // å¦‚æœæ”¶åˆ°ç»“æŸæ ‡å¿—
          if (result.is_final) {
            ws.close()
            resolve(transcription)
          }
        } catch (error) {
          console.error('Failed to parse transcription result:', error)
        }
      }

      ws.onerror = (error) => {
        console.error('WebSocket error:', error)
        reject(new Error('è¯­éŸ³è¯†åˆ«å¤±è´¥'))
      }

      ws.onclose = () => {
        console.log('ğŸ”Œ WebSocket closed')
        if (transcription) {
          resolve(transcription)
        }
      }
    })
  }

  /**
   * åˆ†ç‰‡å‘é€éŸ³é¢‘æ•°æ®
   */
  private async sendAudioData(ws: WebSocket, audioBlob: Blob): Promise<void> {
    const chunkSize = 1024 * 8 // 8KB per chunk
    const arrayBuffer = await audioBlob.arrayBuffer()
    const uint8Array = new Uint8Array(arrayBuffer)

    for (let i = 0; i < uint8Array.length; i += chunkSize) {
      const chunk = uint8Array.slice(i, i + chunkSize)

      if (ws.readyState === WebSocket.OPEN) {
        ws.send(chunk)
        // å¯é€‰ï¼šæ·»åŠ å»¶è¿Ÿä»¥æ¨¡æ‹Ÿå®æ—¶éŸ³é¢‘æµ
        await new Promise(resolve => setTimeout(resolve, 100))
      }
    }

    // å‘é€ç»“æŸæ ‡å¿—
    ws.send(JSON.stringify({ type: 'finish' }))
  }

  /**
   * ä½¿ç”¨æµè§ˆå™¨å†…ç½® Web Speech APIï¼ˆä¸´æ—¶å¼€å‘æ–¹æ¡ˆï¼‰
   * æ³¨æ„ï¼šè¿™ä¸ª API åœ¨ç”Ÿäº§ç¯å¢ƒå¯èƒ½ä¸ç¨³å®šï¼Œä»…ç”¨äºå¼€å‘æµ‹è¯•
   */
  private async transcribeWithWebSpeech(
    audioBlob: Blob,
    options?: TranscriptionOptions
  ): Promise<string> {
    // Web Speech API éœ€è¦å®æ—¶éŸ³é¢‘æµï¼Œæ— æ³•ç›´æ¥å¤„ç† Blob
    // è¿™é‡Œè¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿçš„ç»“æœç”¨äºå¼€å‘æµ‹è¯•

    console.warn('âš ï¸ Using mock transcription (Web Speech API not available for Blob)')

    // æ¨¡æ‹Ÿè½¬å†™å»¶è¿Ÿ
    await new Promise(resolve => setTimeout(resolve, 1000))

    // è¿”å›æ¨¡æ‹Ÿæ–‡æœ¬ï¼ˆå®é™…åº”è¯¥è°ƒç”¨è±†åŒ… APIï¼‰
    return 'è¿™æ˜¯ä¸€æ®µæ¨¡æ‹Ÿçš„è¯­éŸ³è½¬æ–‡æœ¬ç»“æœã€‚è¯·é…ç½®è±†åŒ… API å¯†é’¥ä»¥ä½¿ç”¨çœŸå®çš„è¯­éŸ³è¯†åˆ«åŠŸèƒ½ã€‚'
  }

  /**
   * éªŒè¯ API é…ç½®æ˜¯å¦å®Œæ•´
   */
  isConfigured(): boolean {
    return !!(this.apiKey && this.appId)
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const transcriptionService = new TranscriptionService()
